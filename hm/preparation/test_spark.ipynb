{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a47a1e4-6881-47ee-88be-010ea8022e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- t_dat: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- article_id: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- sales_channel_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"LOOOL\").getOrCreate()\n",
    "\n",
    "df = spark.read.option(\"header\", True).csv(\"../00_data/transactions_train.csv\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b8b2411-a326-415b-af95-db8f6f06161a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+----------+--------------------+----------------+\n",
      "|     t_dat|         customer_id|article_id|               price|sales_channel_id|\n",
      "+----------+--------------------+----------+--------------------+----------------+\n",
      "|2018-09-20|000058a12d5b43e67...|0663713001|0.050830508474576264|               2|\n",
      "|2018-09-20|000058a12d5b43e67...|0541518023| 0.03049152542372881|               2|\n",
      "|2018-09-20|00007d2de826758b6...|0505221004| 0.01523728813559322|               2|\n",
      "|2018-09-20|00007d2de826758b6...|0685687003|0.016932203389830508|               2|\n",
      "|2018-09-20|00007d2de826758b6...|0685687004|0.016932203389830508|               2|\n",
      "|2018-09-20|00007d2de826758b6...|0685687001|0.016932203389830508|               2|\n",
      "|2018-09-20|00007d2de826758b6...|0505221001|0.020322033898305086|               2|\n",
      "|2018-09-20|00083cda041544b2f...|0688873012| 0.03049152542372881|               1|\n",
      "|2018-09-20|00083cda041544b2f...|0501323011|0.053372881355932204|               1|\n",
      "|2018-09-20|00083cda041544b2f...|0598859003|  0.0457457627118644|               2|\n",
      "|2018-09-20|00083cda041544b2f...|0688873020| 0.03049152542372881|               1|\n",
      "|2018-09-20|00083cda041544b2f...|0688873011| 0.03049152542372881|               1|\n",
      "|2018-09-20|0008968c0d451dbc5...|0531310002| 0.02252542372881356|               2|\n",
      "|2018-09-20|0008968c0d451dbc5...|0529841001|0.020322033898305086|               2|\n",
      "|2018-09-20|000aa7f0dc06cd717...|0501820043|0.016932203389830508|               2|\n",
      "|2018-09-20|000aa7f0dc06cd717...|0501820043|0.016932203389830508|               2|\n",
      "|2018-09-20|000aa7f0dc06cd717...|0674681001|0.008457627118644067|               2|\n",
      "|2018-09-20|000aa7f0dc06cd717...|0671505001|0.033881355932203386|               2|\n",
      "|2018-09-20|000aa7f0dc06cd717...|0671505001|0.033881355932203386|               2|\n",
      "|2018-09-20|000aa7f0dc06cd717...|0631848002|0.033881355932203386|               2|\n",
      "+----------+--------------------+----------+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00597ca3-0230-4509-8f69-29a354a54db8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle '_thread.RLock' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rdd \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallelize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kaggle/venv/lib64/python3.8/site-packages/pyspark/context.py:574\u001b[0m, in \u001b[0;36mSparkContext.parallelize\u001b[0;34m(self, c, numSlices)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreateRDDServer\u001b[39m():\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonParallelizeServer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsc\u001b[38;5;241m.\u001b[39msc(), numSlices)\n\u001b[0;32m--> 574\u001b[0m jrdd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serialize_to_jvm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserializer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreader_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreateRDDServer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m RDD(jrdd, \u001b[38;5;28mself\u001b[39m, serializer)\n",
      "File \u001b[0;32m~/kaggle/venv/lib64/python3.8/site-packages/pyspark/context.py:611\u001b[0m, in \u001b[0;36mSparkContext._serialize_to_jvm\u001b[0;34m(self, data, serializer, reader_func, createRDDServer)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 611\u001b[0m         \u001b[43mserializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtempFile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    613\u001b[0m         tempFile\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/kaggle/venv/lib64/python3.8/site-packages/pyspark/serializers.py:211\u001b[0m, in \u001b[0;36mBatchedSerializer.dump_stream\u001b[0;34m(self, iterator, stream)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump_stream\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterator, stream):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batched\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kaggle/venv/lib64/python3.8/site-packages/pyspark/serializers.py:133\u001b[0m, in \u001b[0;36mFramedSerializer.dump_stream\u001b[0;34m(self, iterator, stream)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump_stream\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterator, stream):\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m--> 133\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_with_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kaggle/venv/lib64/python3.8/site-packages/pyspark/serializers.py:143\u001b[0m, in \u001b[0;36mFramedSerializer._write_with_length\u001b[0;34m(self, obj, stream)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_write_with_length\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj, stream):\n\u001b[0;32m--> 143\u001b[0m     serialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m serialized \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialized value should not be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/kaggle/venv/lib64/python3.8/site-packages/pyspark/serializers.py:427\u001b[0m, in \u001b[0;36mPickleSerializer.dumps\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdumps\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj):\n\u001b[0;32m--> 427\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle '_thread.RLock' object"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdcb6e2-c990-4130-bc03-4663943efa01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
